{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# HRTFs\nExample showing the use of HRTFs in Brian hears. Note that you will need to\ndownload the `.IRCAM_LISTEN` database and set the IRCAM_LISTEN environment variable to point to the location\nwhere you saved it.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from brian2 import *\nfrom brian2hears import *\n# Load database\nhrtfdb = IRCAM_LISTEN()\nhrtfset = hrtfdb.load_subject(hrtfdb.subjects[0])\n# Select only the horizontal plane\nhrtfset = hrtfset.subset(lambda elev: elev==0)\n# Set up a filterbank\nsound = whitenoise(10*ms)\nfb = hrtfset.filterbank(sound)\n# Extract the filtered response and plot\nimg = fb.process().T\nimg_left = img[:img.shape[0]//2, :]\nimg_right = img[img.shape[0]//2:, :]\nsubplot(121)\nimshow(img_left, origin='lower', aspect='auto',\n       extent=(0, sound.duration/ms, 0, 360))\nxlabel('Time (ms)')\nylabel('Azimuth')\ntitle('Left ear')\nsubplot(122)\nimshow(img_right, origin='lower', aspect='auto',\n       extent=(0, sound.duration/ms, 0, 360))\nxlabel('Time (ms)')\nylabel('Azimuth')\ntitle('Right ear')\nshow()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}