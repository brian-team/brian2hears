{
  "nbformat_minor": 0, 
  "nbformat": 4, 
  "cells": [
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "%matplotlib inline"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "\nHRTFs\n-----\nExample showing the use of HRTFs in Brian hears. Note that you will need to\ndownload the `.IRCAM_LISTEN` database and set the IRCAM_LISTEN environment variable to point to the location\nwhere you saved it.\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "from brian2 import *\nfrom brian2hears import *\n# Load database\nhrtfdb = IRCAM_LISTEN()\nhrtfset = hrtfdb.load_subject(hrtfdb.subjects[0])\n# Select only the horizontal plane\nhrtfset = hrtfset.subset(lambda elev: elev==0)\n# Set up a filterbank\nsound = whitenoise(10*ms)\nfb = hrtfset.filterbank(sound)\n# Extract the filtered response and plot\nimg = fb.process().T\nimg_left = img[:img.shape[0]//2, :]\nimg_right = img[img.shape[0]//2:, :]\nsubplot(121)\nimshow(img_left, origin='lower', aspect='auto',\n       extent=(0, sound.duration/ms, 0, 360))\nxlabel('Time (ms)')\nylabel('Azimuth')\ntitle('Left ear')\nsubplot(122)\nimshow(img_right, origin='lower', aspect='auto',\n       extent=(0, sound.duration/ms, 0, 360))\nxlabel('Time (ms)')\nylabel('Azimuth')\ntitle('Right ear')\nshow()"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }
  ], 
  "metadata": {
    "kernelspec": {
      "display_name": "Python 2", 
      "name": "python2", 
      "language": "python"
    }, 
    "language_info": {
      "mimetype": "text/x-python", 
      "nbconvert_exporter": "python", 
      "name": "python", 
      "file_extension": ".py", 
      "version": "2.7.15", 
      "pygments_lexer": "ipython2", 
      "codemirror_mode": {
        "version": 2, 
        "name": "ipython"
      }
    }
  }
}