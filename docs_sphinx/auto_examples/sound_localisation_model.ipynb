{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Sound localisation model\nExample demonstrating the use of many features of Brian hears, including\nHRTFs, restructuring filters and integration with Brian. Implements a\nsimplified version of the \"ideal\" sound localisation model from Goodman\nand Brette (2010).\n\nThe sound is played at a particular spatial location (indicated on the final\nplot by a red +). Each location has a corresponding assembly of neurons, whose\nsummed firing rates give the sizes of the blue circles in the plot. The most\nstrongly responding assembly is indicated by the green x, which is the estimate\nof the location by the model.\n\nNote that you will need to\ndownload the `.IRCAM_LISTEN` database and set the ``IRCAM_LISTEN`` environment\nvariable to point to the location where you saved it.\n\nReference:\n\n`Goodman DFM, Brette R (2010). Spike-timing-based computation in sound\nlocalization. PLoS Comput. Biol. 6(11) <http://www.ploscompbiol.org/article/info:doi/10.1371/journal.pcbi.1000993>`__.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from brian2 import *\nfrom brian2hears import *\n\n# Download the IRCAM database, and replace this filename with the location\n# you downloaded it to\nhrtfdb = IRCAM_LISTEN()\nsubject = hrtfdb.subjects[0]\nhrtfset = hrtfdb.load_subject(subject)\n# This gives the number of spatial locations in the set of HRTFs\nnum_indices = hrtfset.num_indices\n# Choose a random location for the sound to come from\nindex = randint(hrtfset.num_indices)\n# A sound to test the model with\nsound = Sound.whitenoise(500*ms)\n# This is the specific HRTF for the chosen location\nhrtf = hrtfset.hrtf[index]\n# We apply the chosen HRTF to the sound, the output has 2 channels\nhrtf_fb = hrtf.filterbank(sound)\n# We swap these channels (equivalent to swapping the channels in the\n# subsequent filters, but simpler to do it with the inputs)\nswapped_channels = RestructureFilterbank(hrtf_fb, indexmapping=[1, 0])\n# Now we apply all of the possible pairs of HRTFs in the set to these\n# swapped channels, which means repeating them num_indices times first\nhrtfset_fb = hrtfset.filterbank(Repeat(swapped_channels, num_indices))\n# Now we apply cochlear filtering (logically, this comes before the HRTF\n# filtering, but since convolution is commutative it is more efficient to\n# do the cochlear filtering afterwards\ncfmin, cfmax, cfN = 150*Hz, 5*kHz, 40\ncf = erbspace(cfmin, cfmax, cfN)\n# We repeat each of the HRTFSet filterbank channels cfN times, so that\n# for each location we will apply each possible cochlear frequency\ngfb = Gammatone(Repeat(hrtfset_fb, cfN),\n                tile(cf, hrtfset_fb.nchannels))\n# Half wave rectification and compression\ncochlea = FunctionFilterbank(gfb, lambda x:15*clip(x, 0, Inf)**(1.0/3.0))\n# Leaky integrate and fire neuron model\neqs = '''\ndV/dt = (I-V)/(1*ms)+0.1*xi/(0.5*ms)**.5 : 1 (unless refractory)\nI : 1\n'''\nG = FilterbankGroup(cochlea, 'I', eqs, reset='V=0', threshold='V>1', refractory=5*ms, method='Euler')\n# The coincidence detector (cd) neurons\ncd = NeuronGroup(num_indices*cfN, eqs, reset='V=0', threshold='V>1', refractory=1*ms, method='Euler', dt=G.dt[:])\n# Each CD neuron receives precisely two inputs, one from the left ear and\n# one from the right, for each location and each cochlear frequency\nC = Synapses(G, cd, on_pre='V += 0.5', dt=G.dt[:])\nC.connect(j='i', skip_if_invalid=True)\nC.connect(j='i-num_indices*cfN', skip_if_invalid=True)\n# We want to just count the number of CD spikes\ncounter = SpikeMonitor(cd, record=False)\n# Run the simulation, giving a report on how long it will take as we run\nrun(sound.duration, report='stderr')\n# We take the array of counts, and reshape them into a 2D array which we sum\n# across frequencies to get the spike count of each location-specific assembly\ncount = counter.count[:].copy()\ncount.shape = (num_indices, cfN)\ncount = sum(count, axis=1)\ncount = array(count, dtype=float)/amax(count)\n# Our guess of the location is the index of the strongest firing assembly\nindex_guess = argmax(count)\n# Now we plot the output, using the coordinates of the HRTFSet\ncoords = hrtfset.coordinates\nazim, elev = coords['azim'], coords['elev'] \nscatter(azim, elev, 100*count)\nplot([azim[index]], [elev[index]], '+r', ms=15, mew=2)\nplot([azim[index_guess]], [elev[index_guess]], 'xg', ms=15, mew=2)\nxlabel('Azimuth (deg)')\nylabel('Elevation (deg)')\nxlim(-5, 350)\nylim(-50, 95)\nshow()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}